\chapter{Background}
\label{chapter:background}

\section{Distributed locking}

A Distributed System is defined by \citet[\p{2}]{coulouris2005distributed} as 
hardware or software components of networked computers performing activities by
communicating with each other only by passing messages. Said definition gives
it attributes such as concurrency%
\sidenote[3]{
  \emph{Concurrency}: Simultaneous execution of processes (may or may not be 
  in parallel).
}, non usage of global clock%
\sidenote[5]{
  \emph{No global clock}: The computers in the distributed system are not 
  co-ordinated using a single global clock and use other mechanisms such as
  vector clocks \citep{Lamclocks} for it.
}
and ability to handle independent failures
\sidenote[11]{
  \emph{Independent failures}: Failure of individual computers does not lead
  to the failure of the entire system but, rather has other consequences such
  as degraded performance.
}.

One of the ways to co-ordinate concurrent processes in a loosely coupled 
distributed system is to use a distributed lock manager. It helps such
processes to synchronize their activities or to serialize their access to
shared resources.

A distributed lock manager can be implemented in many different ways. We use
Paxos, a consensus algorithm as our system is asynchronous.

\section{Consensus algorithm}

\citet{Lamclocks} first suggested that distributed systems can be modelled as
state machines. The system as a whole makes progress when these state machines
transition between states based on events. The events are  generated by passing
messages between the networked machines. To ensure that all the servers in the
system are at the same state, they need to agree on sequence of these messages.

Consensus is arriving at a single decision by the agreement of participants in a
group. Consensus algorithms allows a group of connected processes agree with 
each other, which is important in case of failures. Solving consensus allows
us to use it as a primitive to solve more advanced problems in distributed
computing such as atomic commits and totally ordered broadcasts. This is a
primitive that is related to lot of other agreement problems \citep{GS01}.

In an asynchronous network, consensus is simple when there are no faults, but
gets tricky otherwise \citep{Lampson:1996:HBH}. Further more, in such a network,
no algorithm exists that can reach consensus in case of even one faulty process
\citep{FisLynPat85}.

Paxos is one of many available consensus algorithms but, its core is the best
known asynchronous consensus algorithm \citep{Lampson:1996:HBH}. It is covered
in more detail in \sectionref{paxos}.

\section{CAP Theorem}

The \abbr{CAP} theorem or Brewer's conjecture states that it is not 
possible to achieve consistency%
\sidenote{
  \emph{Consistency}: Requests sent to a distributed system is said to be
  consistent if the result of the request is the same as compared to sending
  the the request to a single node executing the request one by one.
}, availability%
\sidenote[6]{
  \emph{Available}: Every request sent to the system must eventually terminate.
}
and partition tolerance%
\sidenote[9]{
  \emph{Partition tolerance}: Communication loss between set of nodes in the
  network.
}
at the same time in an asynchronous network model
\citep{journals/sigact/GilbertL02}. A choice of two of these attributes must
be made when designing a system in such a network.

In this project, we focus mainly on consistency and partition tolerance 
as a primary goals with availability as a secondary goal.

\section{Challenges}

Building a distributed system has its own set of challenges. We identify the
important ones below and address them in the design section.

\subsection{Scale}

Scaling in this context refers to increase in throughput by increasing the
number of machines in the network. However, in the case of a distributed 
consensus based locking system, the throughput is inversely proportional to the
number of nodes in the network since it involves more messages and possibly
more phases needed for agreement.

\subsection{Configuration}

Distributed systems need to plan ahead in terms of handling node failures and
should provide ways to replace failed nodes. The system needs to support dynamic
configuration to allow increasing and decreasing the cluster size as required.

\subsection{Failure tolerance}

The set of servers a distributed system is made of susceptable to failures.
Machines occasionally fail, messages can be lost in transit, networks can be
partitioned, disk drives can fail and so on. The system should be able to
isolate the failures and make sure that it can function despite such failures.

One way to classify such failures is Byzantine%
\sidenote{
  \emph{Byzantine Failure}: A faulty component sends conflicting messages to
  different parts of the system.
}
and non-byzantine%
\sidenote[3]{
  \emph{Non-byzantine Failure}: A component either sends or doesn't send the
  message.
}
depending on its origin. The software should be robust enough to tolerate such
failures. This project only deals with non-byzantine failures.

\subsection{Finding and Fixing Bugs}

Many things can go wrong in a distributed system 
\citep{Rotem-gal-oz_fallaciesof}. The algorithms can be hard to implement, 
minute logical errors in the implementation could cause race conditions and
it is hard to estimate time and message complexities in advance. This makes it
hard to discover bugs, reproduce them, find its source and fix them.

\subsection{Testing}

Testing distributed systems is a hard problem \citep{BoyCPW2003}.
Different types of tests such as unit tests%
\sidenote{
  \emph{Unit Testing}: Testing individual "units" of code.
}, integration tests%
\sidenote[2]{
  \emph{Integration Testing}: Testing that different components of the system
  work together.
}, system tests%
\sidenote[4]{
  \emph{System Testing}: Testing the system as a while works well and meets
  specified requirements.
}, load tests%
\sidenote[7]{
  \emph{Load Testing}: Amount of traffic the system can safely handle.
}
are needed for a robust implementation. Furthermore, the implementation needs
to be tested with different cluster sizes.

