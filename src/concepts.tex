\chapter{Concepts}
\label{chapter:concepts}

We discuss the various concepts discussed in the thesis scope in this chapter.

\section{Paxos}

The consensus algorithm used in the system is Paxos \sectionref{paxos}. 
\citet{Robbert2011} is the specific paper referred to for the implementation of
Warlock. This section describes the specific flavour of the algorithm.

The processes of the group can be classified into different roles based on the
part of algorithm they are responsible for.

\begin{itemize}
    \iterm{Replica}: Replicas are processes responsible for assigning proposal 
    number to an operation and handle decisions made.
    \iterm{Acceptor}: Acceptors are the ``memory'' of the algorithm. They keep
    track of which leader is currrently in-charge to issue commands.
    \iterm{Leader}: Leaders receive proposals from replicas and they try to
    co-ordinate the messaging to acceptors for that proposal. It uses ballots%
    \sidenote{
      \emph{Ballots} are monotonically increasing ids that are unique to a 
      specific leader. Each leader has an infinite number of ballots.
    }
    to track the execution order or proposals.
    \iterm{Scout}: A scout process is spawned by the leader to active a specific
    ballot.
    \iterm{Commander}: A commander process is spawned by the leader to try
    and get votes for a specific proposal.
\end{itemize}

Assuming the scout was already run and the current leader has its ballot as the
largest one, lets see a typical flow of the proposal from its intiation to its
execution skipping on the smaller details and corner cases.

\begin{itemize}
    \item A proposal is created by the client based on the request. This 
      proposal is uniquely identified and contains all the necessary request 
      information. This proposal is sent to the replica.
    \item The replica checks if the propsal is a duplicate and if not it
      assigs a sequence number%
      \sidenote{
        The replica is resposible for maintaning a consistent log of operations.
        This log is made up of slots with each of the slots indexed by a 
        sequence number.
      }
      to it before sending it off to the leader.
    \item The leader, which already has run the scout, spawns a commander with
      the ballot and proposal information.
    \item The commander sends out a message to all acceptors with the ballot
      information to all acceptors asking them to approve the proposal.
    \item The acceptors respond positively if it has not seem another larger
      ballot number and negatively otherwise.
    \item The commander waits for a quorum (usually a majority of total 
      acceptors) of acceptors. Once it has received majority of the approvals,
      the commander asks all the replicas to execute the proposal and exits.
    \item The replica checks if the received decision is the next index on
      the consistent log and executes the proposal if it is.
\end{itemize}

The paper details several optimizations to make the algorithm more practical.

\section{Erlang}

Erlang \citep{erlang} is a virtual machine based general purpose functional 
programming language built by Ericsson mainly to develop telephony applications 
\citep{Armstrong07}. Erlang was build to handle large number of network
requests with special attention given to handling failures.

A process is the concurrency primitive of Erlang. Each of the processes are 
isolated and have access to their own private memory. This allows us to build
large scale applications with the Actor model%
\sidenote{
  An actor is a process that can
  \begin{inparaenum}[(i)]
    \item Send messages to other actors.
    \item Spawn new actors.
    \item Specify the behaviour to be used when it receives its next message.
  \end{inparaenum}
}
\citep{Clinger81}.

Erlang also supports hot code loading which allows us to upgrade the system's
code without restarting or disrupting the service.

The ideas of concurrency, fault tolerance, distributabilityi, hot code loading
behind Erlang maps well on to the building large web applications.

\todo{Add and arrange features}

\section{Open Telecom Platform}

Open Telecom Platorm (OTP) is a collection of Erlang libraries. The OTP code is
well tested, robust and provide design patterns allowing us to quickly build 
Erlang applications.

OTP provides a set of principles for structuring code:

\begin{itemize}
    \iterm{Supervision}: Supervisors are processes that monitor workers 
    processes and restart them based on a pre-defined set of rules. An 
    application can be designed in the form of a tree with fine grained
    control to handle crashing processes and to localize such crashes.
    \iterm{Behaviours}: Behaviours are commonly used Erlang design patterns.
    They contain a pre-defined set of functions necessary to implement
    specific design patterns allowing for quick implementation.
    \iterm{Applications}: Logical group of components can be glued together
    to form applications. Applications have well-defined roles and Erlang
    provides convinient modules to manage them.
    \iterm{Releases}: A release is a complete system packaged for deployment.
    Erlang provides modules necessary to create packages for deploying new
    code and upgrading existing code.
\end{itemize}

\section{Erlang libraries}

A few external projects were used for building this system. We describe the
roles of these project.

\subsection{lager}

Lager \citep{lager} is a logging framework for Erlang applications. It provides
features such as fine grained log levels, multiple backend support, optimized
logging and relatively better performance.

\subsection{eredis}

eRedis \citep{eredis} is a non-blocking Erlang client library for Redis.

eRedis is used in this project to support the Redis backend and is used in the
implementation of Redis protocol support.

\subsection{Ranch}

Ranch \citep{ranch} is a socket acceptor pool for TCP protocols.

Ranch is used in this project for accepting and managing multiple client 
connections for the Redis protocol implementation.

